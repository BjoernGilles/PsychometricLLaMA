{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Notebook für die Erzeugung der Fragebogen-Items für das nachtrainierte Modell\n",
        "\n",
        "Für die Ausführung dieses Notebooks ist ein Hugging-Face Account notwendig, in welchem die Lizenzbedinungen von LLaMA 2 akzeptiert wurden. Der Hugging-Face Token muss in das Feld \"SECRET\" eingesetzt werden. Zudem muss der Google Drive verbunden sein und den Modell-Adapter enthalten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmV787GdGaUz"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!sudo fuser -v /dev/nvidia* -k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVm-J21tdnXp",
        "outputId": "7b5cc886-488b-4ab0-92dd-b992316c9dc5"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "import huggingface_hub\n",
        "huggingface_hub.login(token=\"SECRET\")\n",
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zezalF1aeU6m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        "    GenerationConfig\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "684ee4bd49044154b20c7338a7e568f9",
            "82774ce639114e8886ae0a7723ac0f5b",
            "0206d0b2eee647e8bfd8696756ad009e",
            "107ca1284247428e9265c4828259830f",
            "c1f80126d56148b4a4c378498003b36a",
            "b0b323cd1a8548fab260ce76f0365881",
            "47eb4060a3204df1a265dd57a090a5eb",
            "c6fc84b0512344fdbbb897e97612843e",
            "1b81bd2da26d479d9b8b28845edbbcb8",
            "17f6ae71d24f48fdb8d1caf2cf5ab7c3",
            "3b324c61689d4b7896c3164a73f52beb"
          ]
        },
        "id": "8bWf1bAueuus",
        "outputId": "c5b41e5e-a749-40b9-cd7d-4ebe00fa69a9"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"meta-llama/Llama-2-13b-hf\"\n",
        "adapter_path = \"/content/drive/MyDrive/llama-2-13b_lora/checkpoint-300_ep1/\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "# Fixing some of the early LLaMA HF conversion issues.\n",
        "tokenizer.bos_token_id = 1\n",
        "\n",
        "# Load the model (use f16 for faster inference)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        "    load_in_4bit=True,\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "    )\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, adapter_path)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create generation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnI5Dw28jqBG"
      },
      "outputs": [],
      "source": [
        "tokenizer_with_prefix_space = AutoTokenizer.from_pretrained(model_name_or_path, add_prefix_space=True)\n",
        "\n",
        "def get_tokens_as_list(word_list):\n",
        "    \"Converts a sequence of words into a list of tokens\"\n",
        "    tokens_list = []\n",
        "    for word in word_list:\n",
        "        tokenized_word = tokenizer_with_prefix_space([word], add_special_tokens=False).input_ids[0]\n",
        "        tokens_list.append(tokenized_word)\n",
        "    return tokens_list\n",
        "\n",
        "bad_words = get_tokens_as_list([\"#\",\"##\",\"###\",\"/n\",\"\\n###\",\"###\\n\"])\n",
        "bad_words.append([13])\n",
        "\n",
        "def generate_items_sample_p(prompt, max_new_tokens=200, temperature=0.9, num_return_sequences=15, num_batches=1, top_p=0.90):\n",
        "\n",
        "\n",
        "\n",
        "    config = GenerationConfig(\n",
        "        max_new_tokens=max_new_tokens,  # Maximum length of the generated text\n",
        "        do_sample=True,  # Whether or not to use sampling in generation\n",
        "        temperature=temperature,  # The value used to module the next token probabilities,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        remove_invalid_values=True,\n",
        "        top_p = top_p,\n",
        "        bad_words_ids =bad_words\n",
        "    )\n",
        "\n",
        "    input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input.to('cuda')\n",
        "\n",
        "    out_dec = []\n",
        "    for _ in range(num_batches):\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(**input, generation_config=config)\n",
        "            batch_out_dec = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
        "\n",
        "        for i in range(len(batch_out_dec)):\n",
        "            batch_out_dec[i] = batch_out_dec[i].replace(prompt, \"\")\n",
        "\n",
        "        out_dec.extend(list(dict.fromkeys(batch_out_dec)))\n",
        "\n",
        "        del out\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    del input\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return out_dec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smhyn71iRi0K"
      },
      "source": [
        "# Itemgenerierung für den Fragebogen\n",
        "- Big five\n",
        "- Need for closure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPmL-aNVRhw_"
      },
      "outputs": [],
      "source": [
        "e_prompt = \"\"\"###Construct: Extraversion\n",
        " ###C_definition: Extraversion is a personality characteristic capturing traits like being Talkative, Assertive, Active, Energetic and Outgoing.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "a_prompt = \"\"\"###Construct: Agreeableness\n",
        " ###C_definition: Agreeableness is a personality characteristic capturing traits like being Sympathetic, Kind, Appreciative, Affectionate and Soft-hearted.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "c_prompt = \"\"\"###Construct: Conscientiousness\n",
        " ###C_definition: Conscientiousness is a personality characteristic capturing traits like being Organized, Thorough, Planful, Efficient and Responsible.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "n_prompt = \"\"\"###Construct: Neuroticism\n",
        " ###C_definition: Neuroticism is a personality characteristic capturing traits like being Tense, Anxious, Nervous, Moody, Worrying\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "o_prompt = \"\"\"###Construct: Openness\n",
        " ###C_definition: Openness is a personality characteristic capturing traits like having wide interests and being Imaginative, Intelligent, Original, Insightful.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "nfc_1_na_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "nfc_1_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: Preference for Order\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "nfc_2_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: Preference for Predictability\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "nfc_3_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: Preference for Decisiveness\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "nfc_4_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: Discomfort with Ambiguity\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "nfc_5_prompt = \"\"\"###Construct: Need for Closure\n",
        " ###C_definition: Need for closure can be defined as the desire for an answer on a given topic, any answer compared to confusion and ambiguity. People with a high Need for Closure prefer order, predictability and decisiveness. They feel discomfort with ambiguity and are closed-minded.\n",
        " ###Subconstruct: Closed-Mindedness\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n",
        "\n",
        "oc_1_prompt = \"\"\"###Construct: Organizational Commitment\n",
        " ###C_definition: Organizational Commitmentis the strength of an individual’s identification with and involvement in a particular organization.\n",
        " ###Subconstruct: NA\n",
        " ###S_defintion: NA\n",
        " ###Difficulty: NA\n",
        " ###Inverted: FALSE\n",
        " ###Item:\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generiere Items für die Need for Closure\n",
        "## Generiere Items für die Organizational Commitment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sz4JNxouo3w"
      },
      "outputs": [],
      "source": [
        "# Define the prompts\n",
        "prompts = [nfc_1_prompt,nfc_2_prompt,nfc_3_prompt,nfc_4_prompt,nfc_5_prompt, oc_1_prompt]\n",
        "\n",
        "# Define the parameters\n",
        "invert_values = [\"FALSE\",\"TRUE\"]\n",
        "difficulty_values = [1,5]\n",
        "temperature_values = [1]\n",
        "\n",
        "# Initialize the list to store the outputs\n",
        "outputs = []\n",
        "\n",
        "# Generate items for each prompt with different parameters\n",
        "for i, prompt in enumerate(prompts):\n",
        "    for invert in invert_values:\n",
        "        for difficulty in difficulty_values:\n",
        "            for temperature in temperature_values:\n",
        "                # Update the prompt with the current parameters\n",
        "                updated_prompt = prompt.replace(\"###Inverted: FALSE\", f\"###Inverted: {invert}\").replace(\"###Difficulty: NA\", f\"###Difficulty: {difficulty if difficulty is not None else 'NA'}\")\n",
        "\n",
        "                # Generate the items\n",
        "                items = generate_items_sample_p(updated_prompt, temperature=temperature, max_new_tokens=40,num_return_sequences=10,num_batches=1,top_p = .90)\n",
        "\n",
        "                # Append the items to the list with a key representing the parameters\n",
        "                key = f\"prompt_{i+1}_invert_{invert}_difficulty_{difficulty if difficulty is not None else 'NA'}_temperature_{temperature}\"\n",
        "                outputs.append({key: items})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSAPA6ibwLuq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "outputs_json= json.dumps(outputs)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/llama-2-13b_lora/generated_items_nacherhebung_1.json\", \"w\") as outfile:\n",
        "    outfile.write(outputs_json)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0206d0b2eee647e8bfd8696756ad009e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fc84b0512344fdbbb897e97612843e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b81bd2da26d479d9b8b28845edbbcb8",
            "value": 3
          }
        },
        "107ca1284247428e9265c4828259830f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f6ae71d24f48fdb8d1caf2cf5ab7c3",
            "placeholder": "​",
            "style": "IPY_MODEL_3b324c61689d4b7896c3164a73f52beb",
            "value": " 3/3 [01:59&lt;00:00, 37.44s/it]"
          }
        },
        "17f6ae71d24f48fdb8d1caf2cf5ab7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b81bd2da26d479d9b8b28845edbbcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b324c61689d4b7896c3164a73f52beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47eb4060a3204df1a265dd57a090a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "684ee4bd49044154b20c7338a7e568f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82774ce639114e8886ae0a7723ac0f5b",
              "IPY_MODEL_0206d0b2eee647e8bfd8696756ad009e",
              "IPY_MODEL_107ca1284247428e9265c4828259830f"
            ],
            "layout": "IPY_MODEL_c1f80126d56148b4a4c378498003b36a"
          }
        },
        "82774ce639114e8886ae0a7723ac0f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b323cd1a8548fab260ce76f0365881",
            "placeholder": "​",
            "style": "IPY_MODEL_47eb4060a3204df1a265dd57a090a5eb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b0b323cd1a8548fab260ce76f0365881": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f80126d56148b4a4c378498003b36a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fc84b0512344fdbbb897e97612843e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
