rstatix::anova_test(dv=dist,within = time,wid = prompt)
rstatix::get_anova_table(aov_times)
data_in%>%
group_by(time)%>%
select(time,dist)%>%
ggpubr::ggdensity(x = "dist",facet.by = "time")
ggpubr::ggqqplot(data_in,"dist",facet.by = "time")
data_in%>%
group_by(time)%>%
select(time,dist)%>%
ggpubr::ggdensity(x = "dist",facet.by = "time")
library(lme4)
library(lmerTest)
model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
anova(model_dist)
pairs.panels(data_in)
model_n_dupes <- lmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_n_dupes)
anova(model_n_dupes)
anova(model_n_dupes)
anova(model_n_dupes,type = "II")
summary(model_n_dupes)
model_n_dupes <- glmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in,family="poisson")
summary(model_n_dupes)
anova(model_n_dupes)
anova(model_n_dupes)
summary(model_n_dupes)
intercept_only <- glmer(n_dupes~1+(1|prompt),data = data_in,family="poisson")
intercept_only
summary(intercept_only)
var(data_in$n_dupes)
summary(intercept_only)
var(data_in$n_dupes)
(1.127095-0.08169 )/1.127095
(0.08169 )/1.127095
model_mean_min_dist <- lmer(mean_min_dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_mean_min_dist)
anova(model_mean_min_dist)
intercept_only <- lmer(mean_min_dist~1+(1|prompt),data = data_in)
intercept_only
summary(intercept_only)
summary(model_mean_min_dist)
plot(model_n_dupes)
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
min_original_dist <- min_original_dist[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
colnames(data_in) <- c("prompt","dist")
data_in <- data_in[1:180,]
data_in <- cbind(data_in,n_dupes=n_dupes,mean_min_dist=mean_min_dist)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
keepstrRight <- function(x, n){
substr(x, 1, nchar(x)-n)
}
post_fix <- data_in$prompt%>%substrRight(n = 1)%>%as.factor()
data_in <- data_in[1:180,]
data_in <- cbind(data_in,time= post_fix[1:180])
data_in$prompt <- data_in$prompt%>%
keepstrRight(n=2)
t_09 <- grepl(data_in$prompt,pattern='temperature_0.9')
t_13 <- grepl(data_in$prompt,pattern='temperature_1.3')
temp = rep(NA,180)
temp[t_09] <- "T9"
temp[t_13] <- "T13"
data_in <- cbind(data_in,temp=temp%>%as.factor())
diff = rep(NA,180)
diff_n <- grepl(data_in$prompt,pattern='difficulty_NA')
diff_1 <- grepl(data_in$prompt,pattern='difficulty_1')
diff[diff_n] <- "NA"
diff[diff_1] <- "1"
diff[!diff_1] <- "5"
data_in <- cbind(data_in,diff=as.factor(diff))
inverted = rep(NA,180)
inverted_t <- grepl(data_in$prompt,pattern='invert_TRUE')
inverted[inverted_t] <- "TRUE"
inverted[!inverted_t] <- "FALSE"
data_in <- cbind(data_in,inverted=as.factor(inverted))
data_in$prompt[1]
str_extract(string = data_in$prompt,pattern = "substr(data_in$prompt,1,8)")
substr(data_in$prompt,1,8)
data_in$prompt <- substr(data_in$prompt,1,8)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
aov_times <- data_in%>%
rstatix::anova_test(dv=dist,within = time,wid = prompt)
library(lme4)
library(lmerTest)
model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
anova(model_dist)
intercept_only <- lmer(dist~1+(1|prompt),data = data_in)
intercept_only
summary(intercept_only)
218/228
218/328
pairs.panels(data_in)
model_n_dupes <- glmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in,family="poisson")
summary(model_n_dupes)
anova(model_n_dupes)
intercept_only <- glmer(n_dupes~1+(1|prompt),data = data_in,family="poisson")
intercept_only
summary(intercept_only)
var(data_in$n_dupes)
(0.007928)/1.127095
summary(intercept_only)
model_mean_min_dist <- lmer(mean_min_dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_mean_min_dist)
summary(model_n_dupes)
data_long%>%
group_by(time,prompt)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
select(n_dupes,mean_min_dist,dist)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
select(n_dupes,mean_min_dist,dist,time,prompt)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
select(n_dupes,time,prompt)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
select(mean_min_dist,dist,time,prompt)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time,prompt)%>%
select(mean_min_dist,time,prompt)%>%
rstatix::get_summary_stats()
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
duplicates <- duplicates[,-1]
min_original_dist_no_diff <- min_original_dist_no_diff[,-1]
n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()
n_dupes_no_diff
n_dupes
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
n_dupes
n_dupes_no_diff
duplicates_no_diff
duplicates_no_diff <- duplicates_no_diff[,-1]
min_original_dist <- min_original_dist[,-1]
min_original_dist_no_diff <- min_original_dist_no_diff[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()
n_dupes_no_diff
n_dupes
mean_min_dist_no_diff <- apply(min_original_dist_no_diff,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
mean_min_dist_no_diff
mean_min_dist
mean_min_dist
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
mean_min_dist
mean_min_dist
mean_min_dist_no_diff
t.test(mean_min_dist,mean_min_dist_no_diff)
t.test(mean_min_dist,mean_min_dist_no_diff,var.equal = FALSE)
describe(mean_min_dist)
describe(mean_min_dist_no_diff)
describe(mean_min_dist)
describe(mean_min_dist_no_diff)
describe(n_dupes)
describe(n_dupes)
describe(n_dupes_no_diff)
describe(n_dupes_no_diff)
duplicates
duplicates_no_diff
duplicates_no_diff
duplicates_no_diff
colnames(data_no_diff) <- c("prompt","dist")
View(data_no_diff)
data_no_diff <- data_in[1:20,]
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
#data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
#duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
#min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
min_original_dist <- min_original_dist[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
describe(mean_min_dist)
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
#data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
#duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
#min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
#duplicates_no_diff <- duplicates_no_diff[,-1]
min_original_dist <- min_original_dist[,-1]
#min_original_dist_no_diff <- min_original_dist_no_diff[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
#n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()
describe(n_dupes)
'   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 180 1.25 1.06      1    1.15 1.48   0   5     5 0.66     0.02 0.08'
#describe(n_dupes_no_diff)
'   vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 20  0.7 0.66      1    0.62 0.74   0   2     2 0.34    -0.93 0.15'
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
#mean_min_dist_no_diff <- apply(min_original_dist_no_diff,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
#t.test(mean_min_dist,mean_min_dist_no_diff,var.equal = FALSE)
describe(mean_min_dist)
#describe(mean_min_dist_no_diff)
colnames(data_in) <- c("prompt","dist")
colnames(data_no_diff) <- c("prompt","dist")
colnames(data_in) <- c("prompt","dist")
#colnames(data_no_diff) <- c("prompt","dist")
data_in <- data_in[1:180,]
#data_no_diff <- data_in[1:20,]
data_in <- cbind(data_in,n_dupes=n_dupes,mean_min_dist=mean_min_dist)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
keepstrRight <- function(x, n){
substr(x, 1, nchar(x)-n)
}
post_fix <- data_in$prompt%>%substrRight(n = 1)%>%as.factor()
data_in <- data_in[1:180,]
data_in <- cbind(data_in,time= post_fix[1:180])
data_in$prompt <- data_in$prompt%>%
keepstrRight(n=2)
t_09 <- grepl(data_in$prompt,pattern='temperature_0.9')
t_13 <- grepl(data_in$prompt,pattern='temperature_1.3')
temp = rep(NA,180)
temp[t_09] <- "T9"
temp[t_13] <- "T13"
data_in <- cbind(data_in,temp=temp%>%as.factor())
diff = rep(NA,180)
diff_n <- grepl(data_in$prompt,pattern='difficulty_NA')
diff_1 <- grepl(data_in$prompt,pattern='difficulty_1')
diff[diff_n] <- "NA"
diff[diff_1] <- "1"
diff[!diff_1] <- "5"
data_in <- cbind(data_in,diff=as.factor(diff))
inverted = rep(NA,180)
inverted_t <- grepl(data_in$prompt,pattern='invert_TRUE')
inverted[inverted_t] <- "TRUE"
inverted[!inverted_t] <- "FALSE"
data_in <- cbind(data_in,inverted=as.factor(inverted))
data_in$prompt <- substr(data_in$prompt,1,8)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
'aov_times <- data_in%>%
rstatix::anova_test(dv=dist,within = time,wid = prompt)
rstatix::get_anova_table(aov_times)
data_in%>%
group_by(time)%>%
select(time,dist)%>%
ggpubr::ggdensity(x = "dist",facet.by = "time")
ggpubr::ggqqplot(data_in,"dist",facet.by = "time")'
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
pairs.panels(data_in)
data_in%>%
group_by(time)%>%
select(time,dist)%>%
ggpubr::ggdensity(x = "dist",facet.by = "time")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("dist")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("dist")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("n_dupes")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("mean_min_dist")
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
duplicates <- duplicates[,-1]
#duplicates_no_diff <- duplicates_no_diff[,-1]
min_original_dist <- min_original_dist[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
describe(n_dupes)
describe(n_dupes)
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
describe(mean_min_dist)
colnames(data_in) <- c("prompt","dist")
data_in <- data_in[1:180,]
data_in <- cbind(data_in,n_dupes=n_dupes,mean_min_dist=mean_min_dist)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
keepstrRight <- function(x, n){
substr(x, 1, nchar(x)-n)
}
post_fix <- data_in$prompt%>%substrRight(n = 1)%>%as.factor()
data_in <- data_in[1:180,]
data_in <- cbind(data_in,time= post_fix[1:180])
data_in$prompt <- data_in$prompt%>%
keepstrRight(n=2)
t_09 <- grepl(data_in$prompt,pattern='temperature_0.9')
t_13 <- grepl(data_in$prompt,pattern='temperature_1.3')
temp = rep(NA,180)
temp[t_09] <- "T9"
temp[t_13] <- "T13"
data_in <- cbind(data_in,temp=temp%>%as.factor())
diff = rep(NA,180)
diff_n <- grepl(data_in$prompt,pattern='difficulty_NA')
diff_1 <- grepl(data_in$prompt,pattern='difficulty_1')
diff[diff_n] <- "NA"
diff[diff_1] <- "1"
diff[!diff_1] <- "5"
data_in <- cbind(data_in,diff=as.factor(diff))
inverted = rep(NA,180)
inverted_t <- grepl(data_in$prompt,pattern='invert_TRUE')
inverted[inverted_t] <- "TRUE"
inverted[!inverted_t] <- "FALSE"
data_in <- cbind(data_in,inverted=as.factor(inverted))
data_in$prompt <- substr(data_in$prompt,1,8)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
aov_times <- data_in%>%
rstatix::anova_test(dv=dist,within = time,wid = prompt)
rstatix::get_anova_table(aov_times)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("dist")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("n_dupes")
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats("mean_min_dist")
data_in%>%
filter(prompt=="prompt_4")%>%
group_by(time)%>%
rstatix::get_summary_stats("dist")
data_in%>%
filter(prompt=="prompt_4")%>%
group_by(time)%>%
rstatix::get_summary_stats("n_dupes")
data_in%>%
filter(prompt=="prompt_4")%>%
group_by(time)%>%
rstatix::get_summary_stats("mean_min_dist")
library(lme4)
library(lme4)
library(lmerTest)
model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
anova(model_dist)
summary(model_dist)
model_n_dupes <- glmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in,family="poisson")
summary(model_n_dupes)
model_mean_min_dist <- lmer(mean_min_dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_mean_min_dist)
