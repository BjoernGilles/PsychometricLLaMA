# Packete laden

```{r}
library(pacman)

p_load(
  tidyverse,
  stringr,
  psych,
  reticulate
)
```


# Load data
```{r}
pd <- import("pandas")

data <- pd$read_json("bundled_results.json")

data <- t(data)

data <- data%>%
  as.data.frame(row.names = c("12","13","23"))


# Umwandeln in das long format
data_long <- data%>%
  gather(key="time",value = "similarity",V1,V2,V3)

data_long$similarity <- data_long$similarity%>%
  as.numeric()


data_long%>%
  group_by(time)%>%
  ggplot(aes(x=similarity))+
  geom_density()+
  facet_wrap(~time)+
  papaja::theme_apa()


data_long%>%
  group_by(time)%>%
  rstatix::get_summary_stats()

```

# Distanz innerhalb der Outputs

```{r}
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")

```


```{r}
# duplicate frames & min distances berechnen

duplicates <- duplicates[,-1]
#duplicates_no_diff <- duplicates_no_diff[,-1]

min_original_dist <- min_original_dist[,-1]
#min_original_dist_no_diff <- min_original_dist_no_diff[,-1]

n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
#n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()

describe(n_dupes)

'   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 180 1.25 1.06      1    1.15 1.48   0   5     5 0.66     0.02 0.08'

#describe(n_dupes_no_diff)

'   vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 20  0.7 0.66      1    0.62 0.74   0   2     2 0.34    -0.93 0.15'


mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
#mean_min_dist_no_diff <- apply(min_original_dist_no_diff,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()

#t.test(mean_min_dist,mean_min_dist_no_diff,var.equal = FALSE)

describe(mean_min_dist)
#describe(mean_min_dist_no_diff)
```


```{r}
colnames(data_in) <- c("prompt","dist")
#colnames(data_no_diff) <- c("prompt","dist")


data_in <- data_in[1:180,]
#data_no_diff <- data_in[1:20,]

data_in <- cbind(data_in,n_dupes=n_dupes,mean_min_dist=mean_min_dist)

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

keepstrRight <- function(x, n){
  substr(x, 1, nchar(x)-n)
}

post_fix <- data_in$prompt%>%substrRight(n = 1)%>%as.factor()

data_in <- data_in[1:180,]

data_in <- cbind(data_in,time= post_fix[1:180])

data_in$prompt <- data_in$prompt%>%
  keepstrRight(n=2)


t_09 <- grepl(data_in$prompt,pattern='temperature_0.9')
t_13 <- grepl(data_in$prompt,pattern='temperature_1.3')

temp = rep(NA,180)

temp[t_09] <- "T9"
temp[t_13] <- "T13"

data_in <- cbind(data_in,temp=temp%>%as.factor())

diff = rep(NA,180)

diff_n <- grepl(data_in$prompt,pattern='difficulty_NA')
diff_1 <- grepl(data_in$prompt,pattern='difficulty_1')

diff[diff_n] <- "NA"
diff[diff_1] <- "1"
diff[!diff_1] <- "5"

data_in <- cbind(data_in,diff=as.factor(diff))

inverted = rep(NA,180)

inverted_t <- grepl(data_in$prompt,pattern='invert_TRUE')

inverted[inverted_t] <- "TRUE"
inverted[!inverted_t] <- "FALSE"

data_in <- cbind(data_in,inverted=as.factor(inverted))


data_in$prompt <- substr(data_in$prompt,1,8)


data_in%>%
  group_by(time)%>%
  rstatix::get_summary_stats()


data_in%>%
  group_by(time)%>%
  select(time,dist)%>%
  ggpubr::ggdensity(x = "dist",facet.by = "time")

ggpubr::ggqqplot(data_in,"dist",facet.by = "time")
```
# Test for dist, n_dupes and mean_min_dist

```{r}
data_in%>%
  group_by(time)%>%
  rstatix::get_summary_stats("dist")

'  time  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se    ci
  <fct> <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 1     dist        60  20.8  92.1   58.3  47.0  69.3  22.3  16.8  56.2  17.2  2.23  4.45
2 2     dist        60  20.1  89.7   59.3  44.9  69.9  25.1  20.1  56.8  17.7  2.28  4.57
3 3     dist        60  23.7  77.4   56.0  46.2  63.2  17.0  14.0  53.2  14.8  1.91  3.82'

data_in%>%
  group_by(time)%>%
  rstatix::get_summary_stats("n_dupes")

'  time  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se    ci
  <fct> <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 1     n_dupes     60     0     5      1     0     2     2  1.48  1    1.18  0.152 0.305
2 2     n_dupes     60     0     4      1     1     2     1  1.48  1.5  1.02  0.131 0.263
3 3     n_dupes     60     0     4      1     1     2     1  1.48  1.25 0.932 0.12  0.241'

data_in%>%
  group_by(time)%>%
  rstatix::get_summary_stats("mean_min_dist")

'  time  variable          n   min   max median    q1    q3   iqr   mad  mean    sd    se    ci
  <fct> <chr>         <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 1     mean_min_dist    60  19.3  55.3   35.4  29.6  39.6 10.1   8.45  35.5  7.22 0.932  1.86
2 2     mean_min_dist    60  21.2  49.7   33.0  29.5  38.6  9.13  6.62  34.0  6.17 0.796  1.59
3 3     mean_min_dist    60  20.5  54.4   34.3  30.3  40.2  9.85  8.10  35.3  7.52 0.971  1.94'

```

# Berechnung der Kennwerte fÃ¼r die Variable Exraversion, zum Vergleich mit der Nacherhebung

```{r}
data_in%>%
  filter(prompt=="prompt_4")%>%
  group_by(time)%>%
  rstatix::get_summary_stats("dist")

data_in%>%
  filter(prompt=="prompt_4")%>%
  group_by(time)%>%
  rstatix::get_summary_stats("n_dupes")

data_in%>%
  filter(prompt=="prompt_4")%>%
  group_by(time)%>%
  rstatix::get_summary_stats("mean_min_dist")


  
  
```



# -------------- Explorative analyse, um den Einfluss einzelner Parameter zu untersuchen ----------------


# Fit a random effect model
```{r}
library(lme4)
library(lmerTest)

model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
anova(model_dist)


intercept_only <- lmer(dist~1+(1|prompt),data = data_in)
intercept_only
summary(intercept_only)
#0.6646341 % der Varianz wird durch die Prompt erklaert

pairs.panels(data_in)
```

# Repeat multi level model for number of dupes
```{r}
model_n_dupes <- glmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in,family="poisson")
summary(model_n_dupes)
anova(model_n_dupes)


intercept_only <- glmer(n_dupes~1+(1|prompt),data = data_in,family="poisson")
intercept_only
summary(intercept_only)
var(data_in$n_dupes)
(0.007928)/1.127095
#7.24% erklaert durch Unterschiede in Prompts?
# (1.127095-0.08169 )/1.127095
```
# Check influence for the mean min distance

```{r}
model_mean_min_dist <- lmer(mean_min_dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_mean_min_dist)
anova(model_mean_min_dist)


intercept_only <- lmer(mean_min_dist~1+(1|prompt),data = data_in)
intercept_only
summary(intercept_only)
```

```{r}
data_in%>%
  group_by(time,prompt)%>%
  select(n_dupes,time,prompt)%>%
  rstatix::get_summary_stats()

data_in%>%
  group_by(time,prompt)%>%
  select(mean_min_dist,time,prompt)%>%
  rstatix::get_summary_stats()


```


