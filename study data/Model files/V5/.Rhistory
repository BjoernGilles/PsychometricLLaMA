library(pacman)
p_load(psych,tidyverse, stringr, rjson, reticulate, TTR
)
pd <- import("pandas")
library(data.table)
train_log <- pd$read_json("trainer_state.json")
log <- rbindlist(l = train_log$log_history,fill = TRUE)
log <- log %>%
filter(loss!=0)
lm(data=log,loss~epoch)%>%summary()
log <- log %>%
mutate(sd= runSD(loss))
log$sd
ggpubr::ggscatter(log,"epoch","loss",add = "reg.line")
ggpubr::ggscatter(log,"epoch","loss",add = "reg.line")
ggpubr::ggscatter(log,"epoch","loss",add = "loess")
ggpubr::ggscatter(log,"epoch","loss",add = "loess")
ggpubr::ggscatter(log,"epoch","loss",add = c("loess","reg.line"))
ggpubr::ggscatter(log,"epoch","loss",add = c("loess"))
ggpubr::ggscatter(log,"epoch","loss",add = c("loess"))
ggpubr::ggscatter(log,"epoch","sd",add = "loess", cor.coef = TRUE,cor.method = "spearman")
ggpubr::ggscatter(log,"epoch","sd",add = "loess", cor.coef = TRUE,cor.method = "spearman")
log%>%
filter(!is.na(sd))%>%
lm(formula = sd~epoch+I(epoch^2)+I(epoch^3))%>%summary()
#64.5%
log%>%
filter(!is.na(sd))%>%
lm(formula = sd~poly(epch,3))%>%summary()
#64.5%
log%>%
filter(!is.na(sd))%>%
lm(formula = sd~poly(epoch,3))%>%summary()
ggpubr::ggscatter(log,"epoch","loss",add = c("loess"))
ggpubr::ggscatter(log,"epoch","loss",add = c("loess"))
View(log)
library(pacman)
p_load(psych,tidyverse, stringr, rjson, reticulate, TTR
)
pd <- import("pandas")
pd <- import("pandas")
library(data.table)
train_log <- pd$read_json("trainer_state.json")
log <- rbindlist(l = train_log$log_history,fill = TRUE)
log <- log %>%
filter(loss!=0)
ggpubr::ggscatter(log,"epoch","loss",add = "reg.line")
ggpubr::ggscatter(log,"epoch","sd",add = "loess", cor.coef = TRUE,cor.method = "spearman")
log <- log %>%
mutate(sd= runSD(loss))
ggpubr::ggscatter(log,"epoch","sd",add = "loess", cor.coef = TRUE,cor.method = "spearman")
log$epoch
ggpubr::ggscatter(log,"epoch","loss",add = "loess", cor.coef = TRUE,cor.method = "spearman")
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
data_in <- readxl::read_xlsx("output_distances.xlsx")
duplicates <- readxl::read_xlsx("duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("distances_min_list.xlsx")
#data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
#duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
#min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
duplicates_no_diff <- duplicates_no_diff[,-1]
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
#duplicates_no_diff <- duplicates_no_diff[,-1]
min_original_dist <- min_original_dist[,-1]
#min_original_dist_no_diff <- min_original_dist_no_diff[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
#n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()
describe(n_dupes)
'   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 180 1.25 1.06      1    1.15 1.48   0   5     5 0.66     0.02 0.08'
#describe(n_dupes_no_diff)
'   vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 20  0.7 0.66      1    0.62 0.74   0   2     2 0.34    -0.93 0.15'
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
mean_min_dist_no_diff <- apply(min_original_dist_no_diff,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
library(pacman)
p_load(
tidyverse,
stringr,
psych,
rjson,
reticulate
)
pd <- import("pandas")
data <- pd$read_json("bundled_results.json")
data <- pd$read_json("../bundled_results.json")
data <- t(data)
data <- data%>%
as.data.frame(row.names = c("12","13","23"))
data_long <- data%>%
gather(key="time",value = "similarity",V1,V2,V3)
data_long$similarity <- data_long$similarity%>%
as.numeric()
data_long%>%
group_by(time)%>%
ggplot(aes(x=similarity))+
geom_density()+
facet_wrap(~time)+
papaja::theme_apa()
data_long%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in <- readxl::read_xlsx("../output_distances.xlsx")
duplicates <- readxl::read_xlsx("../duplicate_items.xlsx")
min_original_dist <- readxl::read_xlsx("../distances_min_list.xlsx")
data_no_diff <- readxl::read_xlsx("output_distances_no_diff.xlsx")
duplicates_no_diff <- readxl::read_xlsx("duplicate_items_no_diff.xlsx")
min_original_dist_no_diff <- readxl::read_xlsx("distances_min_list_no_diff.xlsx")
# duplicate frames & min distances berechnen
duplicates <- duplicates[,-1]
duplicates_no_diff <- duplicates_no_diff[,-1]
min_original_dist <- min_original_dist[,-1]
min_original_dist_no_diff <- min_original_dist_no_diff[,-1]
n_dupes <- colSums(duplicates,na.rm = TRUE)%>%unname()
n_dupes_no_diff <- colSums(duplicates_no_diff,na.rm = TRUE)%>%unname()
describe(n_dupes)
'   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 180 1.25 1.06      1    1.15 1.48   0   5     5 0.66     0.02 0.08'
describe(n_dupes_no_diff)
'  vars  n mean  sd median trimmed mad min max range skew kurtosis   se
X1    1 20 1.45 2.8      0    0.81   0   0   8     8  1.5     0.52 0.63'
mean_min_dist <- apply(min_original_dist,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
mean_min_dist_no_diff <- apply(min_original_dist_no_diff,FUN = mean,na.rm=TRUE,MARGIN = 2)%>%unname()
t.test(mean_min_dist,mean_min_dist_no_diff,var.equal = FALSE)
describe(mean_min_dist)
'  vars   n  mean   sd median trimmed  mad   min   max range skew kurtosis   se
X1    1 180 34.94 6.99  34.11   34.64 7.38 19.33 55.33    36 0.38    -0.32 0.52'
describe(mean_min_dist_no_diff)
'  vars  n  mean    sd median trimmed   mad  min   max range  skew kurtosis   se
X1    1 20 32.02 13.37  34.13   32.86 11.71 6.47 54.67  48.2 -0.57    -0.58 2.99'
t.test(mean_min_dist,mean_min_dist_no_diff,var.equal = FALSE)
colnames(data_in) <- c("prompt","dist")
colnames(data_no_diff) <- c("prompt","dist")
data_in <- data_in[1:180,]
data_no_diff <- data_in[1:20,]
data_in <- cbind(data_in,n_dupes=n_dupes,mean_min_dist=mean_min_dist)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
keepstrRight <- function(x, n){
substr(x, 1, nchar(x)-n)
}
post_fix <- data_in$prompt%>%substrRight(n = 1)%>%as.factor()
data_in <- data_in[1:180,]
data_in <- cbind(data_in,time= post_fix[1:180])
data_in$prompt <- data_in$prompt%>%
keepstrRight(n=2)
t_09 <- grepl(data_in$prompt,pattern='temperature_0.9')
t_13 <- grepl(data_in$prompt,pattern='temperature_1.3')
temp = rep(NA,180)
temp[t_09] <- "T9"
temp[t_13] <- "T13"
data_in <- cbind(data_in,temp=temp%>%as.factor())
diff = rep(NA,180)
diff_n <- grepl(data_in$prompt,pattern='difficulty_NA')
diff_1 <- grepl(data_in$prompt,pattern='difficulty_1')
diff[diff_n] <- "NA"
diff[diff_1] <- "1"
diff[!diff_1] <- "5"
data_in <- cbind(data_in,diff=as.factor(diff))
inverted = rep(NA,180)
inverted_t <- grepl(data_in$prompt,pattern='invert_TRUE')
inverted[inverted_t] <- "TRUE"
inverted[!inverted_t] <- "FALSE"
data_in <- cbind(data_in,inverted=as.factor(inverted))
data_in$prompt <- substr(data_in$prompt,1,8)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
'aov_times <- data_in%>%
rstatix::anova_test(dv=dist,within = time,wid = prompt)
rstatix::get_anova_table(aov_times)
data_in%>%
group_by(time)%>%
select(time,dist)%>%
ggpubr::ggdensity(x = "dist",facet.by = "time")
ggpubr::ggqqplot(data_in,"dist",facet.by = "time")'
library(lme4)
library(lme4)
library(lmerTest)
model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
anova(model_dist)
intercept_only <- lmer(dist~1+(1|prompt),data = data_in)
intercept_only
summary(intercept_only)
anova(intercept_only)
pairs.panels(data_in)
data_in$n_dupes
model_n_dupes <- glmer(n_dupes ~ time + temp + diff + inverted+ (1 | prompt), data = data_in,family="poisson")
summary(model_n_dupes)
model_dist <- lmer(dist ~ time + temp + diff + inverted+ (1 | prompt), data = data_in)
summary(model_dist)
corr(data_in)
cor(data_in)
data_in
lm_dist <- lm(dist ~ time + temp + diff + inverted + prompt, data = data_in)
summary(lm_dist)
plot(lm_dist)
plot(lm_dist)
bptest(lm_dist)
lmtest::bgtest(lm_dist)
lmtest::bptest(lm_dist)
lmtest::dwtest(lm_dist)
lmtest::gqtest(lm_dist)
lmtest::bptest(lm_dist)
lmtest::gqtest(lm_dist)
lmtest::hmctest(lm_dist)
lm_dist$residuals %>% kolmogorov.test()
lm_dist$residuals %>% shapiro.test()
summary(lm_dist)
glm_n_dupes <- glm(n_dupes ~ time + temp + diff + inverted + prompt, data = data_in,family="poisson")
summary(glm_n_dupes)
plot(glm_n_dupes)
plot(glm_n_dupes)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
aov_times <- data_in%>%
rstatix::anova_test(dv=dist,within = time,wid = prompt)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
group_by(time,variable)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
group_by(time,variable)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
group_by(variable,time)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
group_by(variable)
data_in%>%
group_by(time,variable)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
arrange(variable,time)
data_in%>%
group_by(time)%>%
rstatix::get_summary_stats()%>%
arrange(variable,time)
